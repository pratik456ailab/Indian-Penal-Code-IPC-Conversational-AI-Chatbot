{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "üèõÔ∏èIndian Penal Code Chatbot: Your Legal Assistant üó£Ô∏è"
      ],
      "metadata": {
        "id": "8tSGHAyN3eF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: Document Loading & Text Extraction"
      ],
      "metadata": {
        "id": "nicnPcOK2Q6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: Document Loading\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install PyPDF2 langchain wget chromadb openai\n",
        "\n",
        "import wget\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Download the IPC PDF file\n",
        "url = \"https://raw.githubusercontent.com/venkatareddykonasani/Datasets/master/IPC/THE_INDIAN_PENAL_CODE.pdf\"\n",
        "file_name = wget.download(url)\n",
        "\n",
        "# Load and extract text\n",
        "reader = PdfReader(file_name)\n",
        "full_text = \"\"\n",
        "\n",
        "for page in reader.pages:\n",
        "    full_text += page.extract_text()\n",
        "\n",
        "# Print first 1000 characters\n",
        "print(\"First 1000 characters:\\n\")\n",
        "print(full_text[:1000])\n",
        "\n",
        "# Print statistics\n",
        "num_lines = full_text.count(\"\\n\")\n",
        "num_words = len(full_text.split())\n",
        "num_characters = len(full_text)\n",
        "\n",
        "print(\"\\n--- Document Statistics ---\")\n",
        "print(\"Lines:\", num_lines)\n",
        "print(\"Words:\", num_words)\n",
        "print(\"Characters:\", num_characters)\n"
      ],
      "metadata": {
        "id": "v7j_1xqS2RRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-2: Split the Text into Chunks"
      ],
      "metadata": {
        "id": "bYf4L1Ry2RTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-2: Chunking the data\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_text(full_text)\n",
        "\n",
        "print(\"Total Chunks:\", len(chunks))\n",
        "print(\"\\nFirst Chunk:\\n\", chunks[0])\n"
      ],
      "metadata": {
        "id": "_PZ5OpX42RV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Creating Embeddings & Storing in Vector Store"
      ],
      "metadata": {
        "id": "0AtM3M4L2RZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Create Embeddings & Store Vector DB\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Create persistent vector store\n",
        "db = Chroma.from_texts(chunks, embeddings, persist_directory=\"IPC_db\")\n",
        "\n",
        "db.persist()\n",
        "\n",
        "print(\"Vector Store created successfully!\")\n"
      ],
      "metadata": {
        "id": "DIuyqOqS2RcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-4: Retrieval + Conversation Setup"
      ],
      "metadata": {
        "id": "Fxx1cHes2ReV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-4: Retrieval and Conversation Chain\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "# Load existing DB\n",
        "vectorstore = Chroma(persist_directory=\"IPC_db\", embedding_function=embeddings)\n",
        "\n",
        "# Create retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Test query\n",
        "query = \"What is the section related to take part in an unlawful assembly or riot?\"\n",
        "result = retriever.get_relevant_documents(query)\n",
        "\n",
        "# Print retrieved documents\n",
        "for doc in result:\n",
        "    print(\"\\nRelevant Text:\\n\", doc.page_content)\n",
        "\n",
        "# Setup Conversation AI\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "conversational_RAG = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory\n",
        ")\n",
        "\n",
        "print(\"Conversational Chain Ready!\")\n"
      ],
      "metadata": {
        "id": "YC7Mpvf32RgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-5: User Conversation"
      ],
      "metadata": {
        "id": "681sHSa32Riu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-5: Chatbot Loop\n",
        "\n",
        "print(\"\\nüìå IPC Chatbot Ready! Type 'quit' to exit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "\n",
        "    if user_input.lower() == \"quit\":\n",
        "        print(\"Chatbot Ended. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    response = conversational_RAG({\"question\": user_input})\n",
        "    print(\"\\nBot:\", response[\"answer\"], \"\\n\")\n"
      ],
      "metadata": {
        "id": "9heAP0N03DHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Queries You Can Try:"
      ],
      "metadata": {
        "id": "Zl757p2y3DKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "What is the section related to take part in an unlawful assembly or riot?\n",
        "What is the punishment for that?\n",
        "What is the Punishment for using a false property mark?\n",
        "Which section deals with that?\n",
        "Which section deals with Counterfeiting currency-notes or bank-notes?\n",
        "Tell me more about the section and punishment for Counterfeiting currency-notes.\n"
      ],
      "metadata": {
        "id": "-yBfn-BC3DOS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}